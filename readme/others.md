# Unassorted Research Works

## Network/Dataset Distillation
- [2014 NeurIPS] **Distilling the Knowledge in a Neural Network**, [[paper]](https://arxiv.org/pdf/1503.02531.pdf), [[bibtex]](/Bibtex/Distilling%20the%20Knowledge%20in%20a%20Neural%20Network.bib), sources: [[peterliht/knowledge-distillation-pytorch]](https://github.com/peterliht/knowledge-distillation-pytorch), [[a7b23/Distilling-the-knowledge-in-neural-network]](https://github.com/a7b23/Distilling-the-knowledge-in-neural-network), [[chengshengchan/model_compression]](https://github.com/chengshengchan/model_compression).
- [2018 NeurIPS] **KDGAN: Knowledge Distillation with Generative Adversarial Networks**, [[paper]](https://papers.nips.cc/paper/7358-kdgan-knowledge-distillation-with-generative-adversarial-networks.pdf), [[bibtex]](/Bibtex/KDGAN%20-%20Knowledge%20Distillation%20with%20Generative%20Adversarial%20Networks.bib), [[homepage]](https://papers.nips.cc/paper/7358-kdgan-knowledge-distillation-with-generative-adversarial-networks), sources: [[xiaojiew1/KDGAN]](https://github.com/xiaojiew1/KDGAN).
- [2018 ArXiv] **Dataset Distillation**, [[paper]](https://arxiv.org/pdf/1811.10959.pdf), [[bibtex]](/Bibtex/Dataset%20Distillation.bib), [[homepage]](https://ssnl.github.io/dataset_distillation/), sources: [[SsnL/dataset-distillation]](https://github.com/SsnL/dataset-distillation).

## Data Imputation
- [2018 ICML] **GAIN: Missing Data Imputation using Generative Adversarial Nets**, [[paper]](https://arxiv.org/pdf/1806.02920.pdf), [[bibtex]](/Bibtex/GAIN%20-%20Missing%20Data%20Imputation%20using%20Generative%20Adversarial%20Nets.bib), sources: [[jsyoon0823/GAIN]](https://github.com/jsyoon0823/GAIN).

## Error Correcting Output Code (ECOC)
- [2016 ArXiv] **N-ary Error Correcting Coding Scheme**, [[paper]](https://arxiv.org/pdf/1603.05850.pdf), [[bibtex]](/Bibtex/N-ary%20Error%20Correcting%20Coding%20Scheme.bib).
- [2018 JIIS] **Experimental Validation for N-ary Error Correcting Output Codes for Ensemble Learning of Deep Neural Networks**, [[paper]](/Documents/Papers/Experimental%20Validation%20for%20N-ary%20Error%20Correcting%20Output%20Codes%20for%20Ensemble%20Learning%20of%20Deep%20Neural%20Networks.pdf), [[bibtex]](/Bibtex/Experimental%20Validation%20for%20N-ary%20Error%20Correcting%20Output%20Codes%20for%20Ensemble%20Learning%20of%20Deep%20Neural%20Networks.bib).

## Recommendation System
- [2018 ArXiv] **Next Item Recommendation with Self-Attention**, [[paper]](https://arxiv.org/pdf/1808.06414.pdf), [[bibtex]](/Bibtex/Next%20Item%20Recommendation%20with%20Self-Attention.bib).
- [2018 ICDM] **Self-Attentive Sequential Recommendation**, [[paper]](https://arxiv.org/pdf/1808.09781.pdf), [[bibtex]](/Bibtex/Self-Attentive%20Sequential%20Recommendation.bib), sources: [[kang205/SASRec]](https://github.com/kang205/SASRec).

## Unassorted Research Works
- [2013 ICML] **Deep Canonical Correlation Analysis**, [[paper]](http://proceedings.mlr.press/v28/andrew13.pdf), [[bibtex]](/Bibtex/Deep%20Canonical%20Correlation%20Analysis.bib), sources: [[VahidooX/DeepCCA]](https://github.com/VahidooX/DeepCCA), [[DTaoo/DCCA]](https://github.com/DTaoo/DCCA), [[msamribeiro/deep-cca]](https://github.com/msamribeiro/deep-cca), [[wangxu-scu/DeepCCA]](https://github.com/wangxu-scu/DeepCCA).
- [2014 EACL] **CCA: Improving Vector Space Word Representations Using Multilingual Correlation**, [[paper]](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi-mLO_-o7bAhVKrY8KHQIDBREQFggmMAA&url=http%3A%2F%2Fanthology.aclweb.org%2FE%2FE14%2FE14-1049.pdf&usg=AOvVaw0C2reHtfMC13b2L5FP6z1F).
- [2015 ICML] **Unsupervised Domain Adaptation by Backpropagation**, [[paper]](http://proceedings.mlr.press/v37/ganin15.pdf), [[bibtex]](/Bibtex/Unsupervised%20Domain%20Adaptation%20by%20Backpropagation.bib), sources: [[shucunt/domain_adaptation]](https://github.com/shucunt/domain_adaptation), [[pumpikano/tf-dann]](https://github.com/pumpikano/tf-dann), [[kskdev/DANN]](https://github.com/kskdev/DANN), [[fungtion/DANN]](https://github.com/fungtion/DANN).
- [2016 JMLR] **Domain-Adversarial Training of Neural Networks**, [[paper]](http://jmlr.org/papers/volume17/15-239/15-239.pdf), [[bibtex]](/Bibtex/Domain-Adversarial%20Training%20of%20Neural%20Networks.bib), sources: [[shucunt/domain_adaptation]](https://github.com/shucunt/domain_adaptation), [[pumpikano/tf-dann]](https://github.com/pumpikano/tf-dann), [[kskdev/DANN]](https://github.com/kskdev/DANN), [[fungtion/DANN]](https://github.com/fungtion/DANN).
- [2016 ICLR] **Distributional Smoothing with Virtual Adversarial Training**, [[paper]](https://arxiv.org/pdf/1507.00677.pdf), [[bibtex]](/Bibtex/Distributional%20Smoothing%20with%20Virtual%20Adversarial%20Training.bib), sources: [[takerum/vat_tf]](https://github.com/takerum/vat_tf), [[lyakaap/VAT-pytorch]](https://github.com/lyakaap/VAT-pytorch), [[takerum/vat]](https://github.com/takerum/vat), [[takerum/vat_chainer]](https://github.com/takerum/vat_chainer/).
- [2017 TIML] **Efficient Methods and Hardware for Deep Learning**, [[Ph.D Thesis]](https://stacks.stanford.edu/file/druid:qf934gh3708/EFFICIENT%20METHODS%20AND%20HARDWARE%20FOR%20DEEP%20LEARNING-augmented.pdf), [[Song Han's homepage]](https://mtlsites.mit.edu/songhan/), [[slides]](https://platformlab.stanford.edu/Seminar%20Talks/retreat-2017/Song%20Han.pdf).
- [2017 NIPS] **SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability**, [[paper]](https://papers.nips.cc/paper/7188-svcca-singular-vector-canonical-correlation-analysis-for-deep-learning-dynamics-and-interpretability.pdf), sources: [[google/svcca]](https://github.com/google/svcca).
- [2017 ArXiv] **One Model To Learn Them All**, [[paper]](https://arxiv.org/abs/1706.05137.pdf), [[blog]](https://blog.acolyer.org/2018/01/12/one-model-to-learn-them-all/).
- [2018 ArXiv] **Tunneling Neural Perception and Logic Reasoning through Abductive Learning**, [[paper]](https://arxiv.org/pdf/1802.01173.pdf).
- [2018 TPAMI] **Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning**, [[paper]](https://arxiv.org/pdf/1704.03976.pdf), [[bibtex]](/Bibtex/Virtual%20Adversarial%20Training%20-%20A%20Regularization%20Method%20for%20Supervised%20and%20Semi-Supervised%20Learning.bib), [[homepage]](https://takerum.github.io), sources: [[takerum/vat_tf]](https://github.com/takerum/vat_tf), [[lyakaap/VAT-pytorch]](https://github.com/lyakaap/VAT-pytorch), [[takerum/vat]](https://github.com/takerum/vat), [[takerum/vat_chainer]](https://github.com/takerum/vat_chainer/).
- [2019 ArXiv] **Implicit Generation and Generalization in Energy-Based Models**, [[paper]](https://arxiv.org/pdf/1903.08689.pdf), [[bibtex]](/Bibtex/Implicit%20Generation%20and%20Generalization%20in%20Energy-Based%20Models.bib), [[homepage]](https://sites.google.com/view/igebm), [[blog]](https://openai.com/blog/energy-based-models/), [[ext. readings]](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf), sources: [[openai/ebm_code_release]](https://github.com/openai/ebm_code_release), [[rosinality/igebm-pytorch]](https://github.com/rosinality/igebm-pytorch).
